---
title: Measure Theory for ML, AI and Diffusion Models
author: Mauro Camara Escudero
date: '2024-02-16'
slug: []
categories: []
tags: []
subtitle: 'A summary of measure theory required for machine learning and artificial intelligence.'
summary: 'Measure Theory for Machine Learning from Scratch'
authors: []
lastmod: '2024-02-16T13:46:31Z'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---
\usepackage{xcolor}
\usepackage{amsthm} 
\theoremstyle{definition}
\newtheorem{def}{Definition}[thm]
**Table of Contents**

- [Randomness, Mathematics, and Intuition](#randomness)
- [Sets and Measures](#sets-and-measures)

# Introduction
In this post, I will cover enough measure theory so that the reader will be able to understand the theory behind Denoising Diffusion Models, and more generally Machine Learning and Artificial Intelligence. To understand measure theory in full, a lot of background mathematical knowledge is required and inevitable, but I will try my best to make things intuitive and yet precise, while assuming **very few prerequisites**. Most importantly, I will always aim to show examples within Probability, Statistics, or Machine Learning, as to keep things on theme. After this post is complete, the plan is to make another one about Stochastic Calculus and SDEs for Machine Learning and Diffusion Models. 

If you find any mistake, typo or for anything else, don't hesitate to contact me. 

<a name="randomness"></a>

# Randomness, Mathematics, and Intuition
In everyday language, we sometimes use the expression "the probability of/that". For instance,

> The <span style="color:darkorange">probability</span> of <span style="color:deepskyblue">rolling a six</span> is <span style="color:#D81159">$1/6$</span>.

I have emphasized in three different colors the key components of that sentence. Measure theory can be used to define each of those three terms rigorously. Specifically, it can answer these questions:

1. What is a probability? (<span style="color:darkorange">orange</span> and <span style="color:#D81159">magenta</span>)
2. What "things" can have an associated probability? (<span style="color:deepskyblue">blue</span>)

All we need are **sets** and **functions**. 

## What this is all about
Until we have built enough measure theory to talk about machine learning, I will often talk about this very simple scenario: A person rolling a six-sided die and observing which number comes out on top. This is a classic and straightforward scenario considered in probability theory, but will allow me to talk about various notions in measure theory without getting lost in the details. I will assume:

- The die will *always* land with exactly one face up, meaning that it will never get stuck in any crack or height difference. Imagine the die is roll on an infinitely long and perfectly flat surface.
- The person will *always* be able to observe which number comes out on top.

Basically, I am making this super easy: the person rolls the die and observes either $1$, $2$, $3$, $4$, $5$, or $6$ written on top. This is known as an **experiment** in probability. I know, rolling a die is hardly an experiment, but the choice of this word is very fitting. It is called an experiment because, **before performing it, we do not know what the outcome of the experiment will be** (otherwise, if the die would always roll a $1$, we would not roll it and board games would be a lot less fun). 

Rolling a die and observing the number on top is just a specific "experiment". The concept of experiment is central to probability theory because whenever we talk about probabilities, we have in mind some sort of experiment, which will result in exactly one outcome, and we are interested in figuring out what is the probability of **some** of these outcomes. I say some because at times we are not interested in the probability of a single outcome, but in the probability of some outcomes. For instance, we may be interested in the probability of <span style="color:deepskyblue">rolling an even number</span>. As we will see soon, we can call **event** the collection of all the "outcomes" that we are interested in.

## Intuition behind probabilities
A probability of something happening is a numeric value that tells us how likely that something is to happen (if this seems circular, that's good, because it is). Ideally, we would like to have a **maximum** probability value for things that are **certain** and a **minimum** probability value for things that are **impossible**. We could choose any two values, but historically, mathematicians have settled for $1$ and $0$ respectively. It makes sense to construct a **function** that takes a "thing" as input and outputs the probability of that thing happening, which is a value in $[0, 1]$.

## Intuition behind events
What "things" can we assign a probability to? Imagine that measure theory has not been developed yet and you find yourself wanting to write the statement above mathematically. What mathematical object can represent the words <span style="color:deepskyblue">rolling a six</span>? A first attempt could be to set it to the number six
$$
\underbrace{\textcolor{deepskyblue}{\text{rolling a six}}}_{\text{everyday language}} = \underbrace{6}_{\text{mathematics}}
$$
This approach doesn't seem to bad because it works seamlessly for other numbers, for instance "rolling a one" would simply be $1$ and so on. However, this approach breaks down when we consider more complicated expressions, for instance, it is not clear how one should "encode"

> Rolling an even number (i.e. either 2, 4, or 6)

using this convention. There are infinitely many natural numbers, so one could potentially encode this and many more complicated expressions for larger and larger numbers. For instance, <span style="color:deepskyblue">rolling an even number</span> could be represented as $7$, and <span style="color:deepskyblue">rolling an odd number</span> could be represented as $8$. There are various issues with this approach, but perhaps the most intuitive to understand is that this way we would have to manually encode each "thing" into a number. Thankfully, there is a better approach.

After attempting to represents "things" with numbers, one may switch to sets. Consider again the task of rolling a six-sided die and observing which number comes on top. We assume that the die cannot get stuck anywhere and always lands on one face or the other, and that we can always observe the number on top. The possible outcomes of this task are that we observe $1$, $2$, $3$, $4$, $5$, or $6$. No other outcome is possible. The phrase <span style="color:deepskyblue">rolling a six</span> could then be encoded as a set
$$
\underbrace{\textcolor{deepskyblue}{\text{rolling a six}}}_{\text{everyday language}} = \underbrace{\{6\}}_{\text{mathematics}}.
$$
You may think that we have not improved the situation by much, since in this set there is only a single element (we say $\{6\}$ is a singleton set). However, this makes talking about more complex "things" a lot easier. For instance, <span style="color:deepskyblue">rolling an even number</span> can be represented by the set containing all the even numbers, and similarly for <span style="color:deepskyblue">rolling an odd number</span>
$$
\underbrace{\textcolor{deepskyblue}{\text{rolling an even number}}}_{\text{everyday language}} = \underbrace{\{2, 4, 6\}}_{\text{mathematics}}.
$$
Sometimes in board games you will need to roll a number above a certain value. This can also be represented easily, for instance 
$$
\underbrace{\textcolor{deepskyblue}{\text{rolling a number larger than three}}}_{\text{everyday language}} = \underbrace{\{4, 5, 6\}}_{\text{mathematics}}.
$$
It turns out, sets are **very flexible** and a great candidate to represent "things" that we want to assign a probability to. Speaking of, all the phrases I have colored in <span style="color:deepskyblue">blue</span> are called **events**. 

> If we can talk about the probability of "something" happening, that something is known as an **event**.

Something that may come as a shock, is that not every set is an event. There are sets for which we cannot talk about their "probability", we will talk more about that later. 

## Intuition behind relationship of probabilities and events
Okay, we can represent events as sets and it seems to be a sensible choice. Now, what does it mean that a certain event has a probability? We need to define the **probability function**. As we expect, this should take *sets* as inputs and return a value between $0$ and $1$, the higher the value, the more likely the event represented by the set, is to happen. Since the function takes sets as inputs, one may think that its domain is the *power set of all possible outcomes*. In other words, if we collect together all outcomes into a single set, which we call the **sample space**
$$
\Omega := \left\{1, 2, 3, 4, 5, 6\right\}
$$
then an event is any subset $\mathsf{E}\subseteq \Omega$. It turns out that when we have finitely many possible outcomes (such as in the die example) this is true, but when we have infinitely many, not all subsets are valid events. In either case, we call **event space** the set of all valid events. By definition, we know that this is a set whose elements are subsets of $\Omega$, but not necessarily *all* subsets. Typically, the event space is denoted by $\mathcal{F}$. In our six-sided die example, $\mathcal{F}$ contains all the subsets (since $\Omega$ has finitely many elements)
$$
\mathcal{F} = 2^\Omega.
$$
For example, $\{2, 4, 6\}\in\mathcal{F}$.

<a name="sets-and-measures"><a/>

# Sigma Algebras
The sigma algebra is the set of all events, i.e. all sets to which we can (and wish) to assign a measure to. One interpretation of a sigma algebra that is helpful for stochastic processes is that a sigma algebra represents information. I will write $2^{\Omega}$ as the *power set* of a set $\Omega$, which is the set of all of its subsets (that's a mouthful).

> **Sigma Algebra**: Let $\Omega$ be a non-empty set. A set $\mathcal{F}\subseteq \mathcal{P}(\Omega)$ is a sigma algebra over $\Omega$ if it satisfies:\
1. $\Omega\in\mathcal{F}$ \
2. Closure under the complementation operation
$$
\mathsf{A}\in\mathcal{F} \implies \Omega\backslash\mathsf{A} \in\mathcal{F}
$$
3. Closure under countable unions
$$
\mathsf{A}_i \in \mathcal{F} \,\,\,\,\,\forall\, i\in\mathcal{I}, \text{ with }|\mathcal{I}|\leq \aleph_0 \implies \bigcup_{i\in\mathcal{I}} \mathsf{A}_i \in\mathcal{F}
$$

Given a non-empty set $\Omega$, we can build several different sigma algebras on it. Some sigma algebras may be contained within larger sigma algebras. In that case, we refer to the smaller sigma algebra as a sub-sigma algebra. In the interpretation of stochastic processes, a sub-sigma algebra represents less information because it contains fewer events. Sub-sigma algebras are generally used for conditioning: they typically represent partial or conditional information. A common nomenclature is to call smaller sigma algebras *coarser* and larger sigma algebras *finer*.

> **Sub-Sigma Algebras**: Let $\Omega$ be a set and $\mathcal{F}$ and $\mathcal{G}$ be two sigma algebras on it. If $\mathcal{G}\subseteq \mathcal{F}$ then we call $\mathcal{G}$ a sub-sigma algebra of $\mathcal{F}$.

The intersection of sigma algebras, is itself a sigma algebra. This is true both for a countable and uncountable number of sigma algebras. The intuition is that the intersection of sigma algebras represents the common or mutual information.

> **Intersection of Sigma Algebras**: Let $\Omega$ be a non-empty set, $\mathcal{I}$ be *any* set and $\{\mathcal{F}_i\,:\, i\in\mathcal{I}\}$ be a collection of sigma algebras on $\Omega$. The intersection of these sigma algebras
$$
\bigcap_{i\in\mathcal{I}} \mathcal{F}_i 
$$
is a sigma algebra over $\Omega$.

Given a bunch of subsets of $\Omega$, it is typically possible to construct several sigma algebras containing all of these subsets. Out of all of these sigma algebras, there is one that is the smallest (or coarser). This is found as the intersection of all possible sigma algebras containing this collection of subsets. The way I make sense of this is that given a bunch of *potential* events, it is possible to find the smallest sigma algebra such that they are *actually* valid events.

> **Sigma algebra generated by a collection of sets**: Let $\Omega$ be a non-empty set and $\mathcal{C}$ be a collection of subsets of $\Omega$. Then the collection $\mathcal{C}$ induces a sigma algebra on $\Omega$, which we call the sigma algebra generated by $\mathcal{C}$, and denote $\sigma(\mathcal{C})$. This sigma algebra is the intersection of all sigma algebras containing $\mathcal{C}$
$$
\sigma(\mathcal{C}) = \bigcap_{\substack{\mathcal{C}\in\mathcal{F} \\\text{sigma algebra}}} \mathcal{F}
$$
and it is the *smallest* sigma algebra containing $\mathcal{C}$.

Since we almost always work with a set $\Omega$ and a sigma algebra on it, for convenience we give a name to the pair $(\Omega, \mathcal{F})$.

>**Measurable Space**: Let $\Omega$ be a non-empty set and $\mathcal{F}\subset\mathcal{P}(\Omega)$ be a sigma algebra on it. The pair $(\Omega, \mathcal{F})$ is called a measurable space, and any set $\mathsf{A}\in\mathcal{F}$ is called $\mathcal{F}$-measurable.

# Topology
By far the most common measurable space you will find in machine learning papers is $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$ for some positive integer $n\in\mathbb{Z}_+$, typically $n=1,2,3$. The sigma algebra $\mathcal{B}(\mathbb{R}^n)$ is called the **Borel** sigma algebra on $\mathbb{R}^n$. But what is it? Its precise definition is, for now, beyond the scope of this post, but I will give some intuition. Given any space with a topology (a topology is a bunch of subsets that represent a notion of "closeness" between elements in the space), one can generate a sigma algebra from this topology, which will be called a Borel sigma algebra.

> **Borel sigma-algebra**: Let $(\mathsf{X}, \tau)$ be a topological space, and $\sigma(\tau)$ be the sigma algebra generated by $\tau$. We call $\sigma(\tau)$ the Borel sigma algebra on $\mathsf{X}$. 

Therefore when we talk about $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$ we are considering the sigma algebra as the Borel sigma algebra generated by the standard topology on $\mathbb{R}$. For completeness, this is (one definition of) what a topology is

> **Topology**: Given a set $\mathsf{X}$, a topology on it is a collection of its subsets $\tau\subseteq 2^{\mathsf{X}}$ such that \
1. Contains the empty set and the set itself: $\emptyset,\mathsf{X}\in\tau$ \
2. Closed under countable and *uncountable* unions.
3. Closed under *finite* intersection.
The elements of $\tau$, which are subsets of $\mathsf{X}$, are known as **open sets**.

At first sight, a topology and a sigma algebra look quite similar. Mathematically, they both contain $\emptyset$ and $\mathsf{X}$, and they are closed under finite unions and intersections, but the difference is that the topology is closed under **uncountable** unions (whereas a sigma algebra only countable), and the sigma algebra is closed under **countable** intersections. Another important difference, perhaps the most important, is that a sigma algebra is closed under complementation, but there is no such requirement in a topology. They are superficially similar objects, but the devil is in the details. Okay, cool, but intuitively what does this mean?  
I have to admit, I struggle to find a valid intuition that is not rooted in mathematical details. However, one way I like to think about it, is that a topology gives you a notion of *closeness* of elements of $\mathsf{X}$, while a sigma algebra gives you the notion of relative sizes of subsets of $\mathsf{X}$. The Borel sigma algebra connects these two concepts. Being generated by the topology, means that every subset in the topology is also an element of the sigma algebra, meaning that we now have both notions! (I know, it ain't much, but it's honest "intuition" work).

# Measures
Measures themselves have nothing to do, per se, with statistics. They are just functions that measure the size (or volume) of something. That something is a set in a sigma algebra. The size of something must be non-negative and if we measure the size of separate things, we should be able to sum them up with no problem. For a bit, I will call a measure $\mathbb{M}$.

> **Measure**: Let $(\Omega, \mathcal{F})$ be a measurable space. A function $\mathbb{M}:\mathcal{F}\to [0, +\infty]$ is called a measure if it satisfies \
1. $\mathbb{M}(\emptyset) = 0$ \
2. Countable additivity: If $\{\mathsf{A}_i\,:\,i\in\mathcal{I}\}$ with $|\mathcal{I}|\leq \aleph_0$ is a countable collection of *pairwise disjoint* sets then
$$
\mathbb{M}\left(\bigcup_{i\in\mathcal{I}} \mathsf{A}_i\right) = \sum_{i\in\mathcal{I}} \mathbb{M}(\mathsf{A}_i)
$$

We need to talk about notation. The size of a set $\mathsf{A}$ under $\mathbb{M}$ is written $\mathbb{M}(\mathsf{A})$, however there is another way of writing this that makes *explicit* the relationship between measures and integration (after all, if measures "measure" the size of things, it makes sense that they are related to integrals, which compute volumes). Indeed we can write
$$
\mathbb{M}(\mathsf{A}) =: \int_{\mathsf{A}}d\mathbb{M} \qquad\qquad\qquad \forall\, \mathsf{A}\in\mathcal{F}.
$$
Brrr, I remember the first time I saw $d\mathbb{M}$ without explanation and I was genuinely confused for days. It looks a bit stark to the eye, and a bit weird and "mathsy". If you are a mathematician, you might hate what I am about to say, but in practice just "forget about it". What I mean by that is that for most situations, you don't need to know the precise definition of the integral above. You just have to "get used" to the notation, and learn how to manipulate it. For me studying mathematics is an endless iteration of pretending you understand new notation until it stops being scary and you can gather up the courage to look at the details and definitions. Think of the expression above as saying that the size of $\mathsf{A}$ under $\mathbb{M}$ is obtained by summing up the size of infinitesimal bits of $\mathsf{A}$. Under this intuition, it is helpful to write down the variable of integration, so we may write (I will choose $\omega$ as variable of integration)
$$
\mathbb{M}(\mathsf{A}) = \int_{\mathsf{A}} \mathbb{M}(d\omega).
$$

Again, as mathematicians we like to give names to things. Just as we typically work with measurable space $(\Omega, \mathcal{F})$, we typically assume that on this measurable space there is a measure $\mathbb{M}$, and hence for brevity call $(\Omega, \mathcal{F}, \mathbb{M})$ a measurable space. Basically, it's just a space where I have a systematic and coherent way of assigning a "size" value to subsets.

> **Measure Space**: A triplet $(\Omega, \mathcal{F}, \mathbb{M})$ is called a measure space if $\mathbb{M}$ is a measure on the measurable space $(\Omega, \mathcal{F})$.

So far, we have talked about measures as assigning "size" to sets. The key intuition that makes measure theory such a wonderful tool for probability theory, is that a probability is fundamentally the size of something *relative to the whole*. What does it mean? It means that the whole space $\Omega$ has a finite size, and so a probability measure assigns to any set $\mathsf{A}\in\mathcal{F}$ its relative size to the whole $\Omega$.

> **Finite Measure**: Let $(\Omega, \mathcal{F}, \mathbb{M})$ be a measure space. We say $\mathbb{M}$ is *finite* if $\mathbb{M}(\Omega) < \infty$. We say $\mathbb{M}$ is $\sigma$-finite if there exists a countable partition $\{\Omega_n\,:\, n\in\mathbb{N}\}$ of $\Omega$ (meaning they are mutually disjoint and their union covers all of $\Omega$) such that $\mathbb{M}(\Omega_n) < \infty$ for each $n\in\mathsf{N}$. 

Any finite measure can be turned into a probability measure by normalization. Often, for a general probability measure I will use the symbol $\mathbb{P}$ rather than $\mathbb{M}$.

> **Probability Measure**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a measurable space with $\mathbb{P}$ being a finite measure. If $\mathbb{P}(\mathsf{X}) = 1$ we say that $\mathbb{P}$ is a probability measure. Notice that given any finite measure $\mathbb{M}$, one can define a corresponding probability measure by normalization $\mathbb{P} := \mathbb{M} / \mathbb{M}(\Omega)$.

Above, I have define $\sigma$-finite measures. What is this property useful for? Typically, this is used for the Radon-Nikodym theorem and Fubini's theorem, which we will see later. In  simpler language: we require $\sigma$-finite measures when we need to work with probability density functions or we need to exchange integrals.

# Random Variables and Distributions

A random variable is a well-behaved function that grabs possible outcomes of an experiments, and maps them to values that are relevant for the problem at hand, and on which we can perform maths. For instance, when flipping a coin, the possible outcomes may be $\Omega = \left\{\text{Head}, \text{Tail}\right\}$, and we note that the two outcomes are *words* and not numbers, in this particular example (in fact, they are not words, but sides of the coin itself). A random variable is a way to *encode* this information more appropriately. In this case, one could map $\text{Head}$ to $0$ and $\text{Tail}$ to $1$ (or vice-versa).

> **Random Variable**: Let $(\Omega, \mathcal{F})$ and $(\mathsf{X}, \mathcal{X})$ be two measurable spaces. A function $\mathrm{X}:\Omega\to\mathsf{X}$ is $\mathcal{F}$-measurable if for every set $\mathsf{B}\in\mathcal{X}$ its preimage $\mathrm{X}^{-1}(\mathsf{B})$ is $\mathcal{F}$-measurable
$$
\mathrm{X}^{-1}(\mathsf{B}) \in\mathcal{F} \qquad\forall\, \mathsf{B}\in\mathcal{X}.
$$
If on the measurable space $(\Omega, \mathcal{F})$ there is a *probability measure* $\mathbb{P}$, then the $\mathcal{X}$-measurable function $\mathrm{X}$ is called a random variable.

Earlier, I said that a random variable encodes information *appropriately*. What do I mean by that? The sigma algebra $\mathcal{X}$ encodes information in terms of subsets of $\mathsf{X}$ (in the case of the coin toss, in terms of $\mathsf{X} = \{0, 1\}$), whereas $\mathcal{F}$ encodes information in terms of the outcomes themselves. A function is a random variable then, whenever the information between these two spaces is *compatible*: Given any piece of information (event) in $\mathcal{X}$, there corresponds a piece of information (again, an event) in $\mathcal{F}$.

The *only* difference between a measurable function and a random variable is that for a measurable function to be *called* a random variable, we require the original space to have an associated probability measure. This is because the whole point of creating a random variable is so that we can study/sample/work with its *distribution*, which we define next. At first, the distribution of a random variable seems quite cryptic, especially if you have never seen pushforward measures before. The idea, is very simple though. A random variable requires an initial probability space $(\Omega, \mathcal{F}, \mathbb{P})$, however we have not said anything about whether or not we have any measure at all on $(\mathsf{X}, \mathcal{X})$, the space where the random variable $\mathrm{X}$ takes values. It turns out that, we can *construct* a probability measure on $(\mathsf{X}, \mathcal{X})$: for any set $\mathsf{A}\in\mathcal{X}$ we first find its preimage with $\mathrm{X}$ and then measure its size with $\mathbb{P}$, this size is the size that the constructed probability measure will assign to it. Notice what we are doing: we are measuring sets in $\mathcal{X}$ using the size of sets in $\mathcal{F}$. This new probability measure is called a **probability distribution** (or just distribution).

> **Distribution**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\mathsf{X}, \mathcal{X})$ be a measurable space and $\mathrm{X}:\Omega\to\mathsf{X}$ be a random variable. Then $\mathsf{X}$ induces a probability measure on $(\mathsf{X}, \mathcal{X})$, called the (probability) distribution of $\mathrm{X}$ and defined as the *pushforward* of $\mathbb{P}$ by $\mathrm{X}$
$$
\mathbb{P}^\mathrm{X} := \mathbb{P}\circ\mathrm{X}^{-1}.
$$
For any measurable set $\mathsf{A}\in\mathcal{X}$ we write $\mathbb{P}^{\mathrm{X}}(\mathsf{A}) = \mathbb{P}(\mathrm{X}^{-1}(\mathsf{A})) = \mathbb{P}(\mathrm{X}\in\mathsf{A})$.

Notice that this is not just a measure: it is a *probability* measure, since $\mathbb{P}^{\mathrm{X}}(\mathsf{X}) = \mathbb{P}(\Omega) = 1$. 

Measure theory is nice because when you don't have something, it gives you the recipe to create it. Remember how before we took any collection of subsets and generated the (smallest) sigma-algebra containing them? Well, given *any function* we can turn it into a measurable function. The trick is that we put into a bag all the preimages of that function and then generate the smallest sigma algebra from this bag. The resulting sigma algebra is then *the smallest (coarser) sigma algebra such that the function is measurable*. 

> **Sigma Algebra generated by a function**: Let $(\mathsf{Y}, \mathcal{Y})$ be a measurable space, $\mathsf{X}$ be a non-empty set and $f:\mathsf{X}\to\mathsf{Y}$ be a function (not necessarily measurable). Then $f$ induces a sigma algebra on $\mathsf{X}$, denoted $\sigma(f)$ 
$$
\sigma(f) := \left\{f^{-1}(\mathsf{A})\,:\, \mathsf{A}\in\mathcal{Y}\right\},
$$
which is the *smallest* sigma algebra on $\mathsf{X}$ such that $f$ is measurable relative to it, indeed by definition $f$ is $\sigma(f)$-measurable. Therefor one could write $\sigma(f) = \sigma\left(\left\{f^{-1}(\mathsf{A})\,:\, \mathsf{A}\in\mathcal{Y}\right\}\right)$.

In most machine learning papers, people do not work with distributions but with *probability density functions (pdf)*, or we can just call them density functions. A distribution is **not** a density function, they are entirely different things, although related. The distribution of a random variable tells you *the probability of events* filtered through the lens of $X$. A density function tells you the **relationship** between two measures, we will see that concept soon enough.

# Expectations
Given a random variable $\mathrm{X}$, its expected value is the "average value" it takes over the possible outcomes, modulated by their probability of occurring, given by $\mathbb{P}$. 

> **Expected value**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\mathsf{X}, \mathcal{X})$ be a measurable space and $\mathrm{X}:\Omega\to\mathsf{X}$ be a random variable. The expected value of $\mathrm{X}$ is
$$
\mathbb{E}[\mathrm{X}] = \int X\, d\mathbb{P} = \int_{\Omega} X(\omega) \mathbb{P}(d\omega).
$$


# Bochner Integration (optional, for nerds)
More generally, one can talk about the Bochner integral. 

> **Bochner integration**: Let $(\Omega, \mathcal{F}, \mathbb{M})$ be a measure space, $(\mathsf{X}, \mathcal{X})$ be a measurable space where $\mathsf{X}$ is a Banach space with norm $|\cdot|_{\mathsf{X}}$ and let $\mathrm{X}:\Omega\to\mathsf{X}$ be a $\mathcal{F}$-measurable function. We say that $\mathrm{X}$ is Bochner integrable if 
$$
\int_{\Omega} |f(\omega)| \, \mathbb{M}(d\omega) < \infty.
$$

Notice that the Radon-Nikodym theorem does not always hold on Banach spaces and instead more conditions are required. Basically, this tells us that if the measure $\mathbb{M}$ is general, we are kind of screwed. Luckily, in machine learning we are typically interested either in $\mathbb{M}$ being some probability measure $\mathbb{P}$ or some other sigma-finite measure such as the Lebesgue 


# $L^p$ Spaces
It is very likely that you will always work on $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$, and the abstraction of this post is not necessary. However, it is *sometimes* essential to understand the theory at a higher abstraction level, hence why I try to keep everything written in terms of arbitrary measurable spaces. However, much of the theory (which you will also find in theoretical machine learning papers) deals with $L^p$ spaces. For this tiny section, we will lose some abstraction. But we will come back to general measure theory soon, don't worry.

We have seen in the Topology section that a topological space $(\mathsf{X}, \tau)$ presents a notion of closeness. We briefly review the intuition behind other spaces. A **vector space** (over a field $\mathsf{F}$) is a space whose elements can be **added together** and **rescaled**, and satisfy the usual properties that we would expect (e.g. associativity, commutativity, distributivity, etc). If we equip a vector space with a norm, we obtain (surprise surprise) a **normed vector space**, where now we have the notion of **length** of vectors (for nerds: in reality, we also need to equip its field with a norm). Automatically, this also gives us a notion of **distance**, since it can be interpreted as the length of the difference of two vectors. If we equip a vector space with an inner product $\langle \cdot, \cdot\rangle$, we get an **inner product space** where now we additionally have the notion of **orientation** of vectors. Any inner product space is also a normed space, since the inner product **induces** a norm
$$
\|v\| = \sqrt{\langle v, v \rangle}.
$$
A **Banach** space is a **complete** normed space. To understand the word "complete" requires a course in analysis, but for our purposes it simply means that we can perform calculus on it, e.g. take limits. A **Hilbert** space is a complete inner product space.

Now, given a measure space $(\Omega, \mathcal{F}, \mathbb{M})$, a measurable space $(\mathsf{X}, \mathcal{X})$ where $\mathsf{X}$ is a Banach space equipped with norm $|\cdot|$, and given a real number $p \geq 1$ we define the following space of functions
$$
L^p(\Omega, \mathcal{F}, \mathbb{M}) := \left\{ f:\Omega\to\mathsf{X} \,\,\left| \,\,  f \text{ is }\mathcal{F}\text{-measurable and } \left(\int |f(\omega)|^p \,\,\mathbb{M}(d\omega)\right)^{1/p} < \infty \right.\right\}
$$
and we **define** the $L^p$-norm as
$$
\|f\|_p := \left(\int |f(\omega)|^p \,\,\mathbb{M}(d\omega)\right)^{1/p}.
$$
$L^p$ spaces are Banach spaces themselves.


# $\pi$-Systems and $\lambda$-Systems

> **$\pi$-system**: Let $\mathsf{P}$ be a non-empty set that is closed under finite intersections, meaning that if $\mathsf{A}, \mathsf{B}\in\mathsf{P}$ then $\mathsf{A}\cap\mathsf{B} \in \mathsf{P}$ and by induction for any $n\in\mathbb{N}$ we have
$$
\bigcap_{i=1}^n \mathsf{A}_i \in \mathsf{P} \qquad \text{ where } \mathsf{A}_i\in\mathsf{P} \,\,\forall\, i=1, \ldots, n
$$

> **$\pi$-system over a set**: Let $\mathsf{X}$ be a non-empty set and $\mathsf{P}\subseteq \mathcal{P}(\mathsf{X})$ be a $\pi$-system whose elements are all subsets of $\mathsf{X}$. Then $\mathsf{P}$ is a $\pi$-system over $\mathsf{X}$.

Of course, since $\mathsf{P}$ is a collection of subsets of $\mathsf{X}$, one can use it to generate a sigma algebra, $\sigma(\mathsf{P})$ over $\mathsf{X}$.

> **$\lambda$-system over a set**: Let $\mathsf{X}$ be a non-empty set and $\mathcal{L}\subseteq \mathcal{P}(\mathsf{X})$ be a collection of subsets of $\mathsf{X}$. Then $\mathsf{L}$ is a $\lambda$-system if \
1. Contains $\mathsf{X}$: $\mathsf{X}\in\mathsf{L}$ \
2. Closed under complementation: $\mathsf{A}\in\mathsf{L} \implies \mathsf{X} \backslash \mathsf{A} \in \mathsf{L}$. \
3. Closed under countable *disjoint* unions: If $\mathsf{A}_i \in \mathsf{L}$ for $i\in\mathcal{I}$ with $|\mathcal{I}|\leq \aleph_0$ and $A_i \cap A_j = \emptyset$ for $i \neq j$ then
$$
\bigcup_{i\in\mathcal{I}} \mathsf{A}_i \in \mathsf{L}.
$$

Importantly, if $\mathcal{S}$ is both a $\pi$-system and a $\lambda$-system over the non-empty set $\mathsf{X}$, then automatically $\mathcal{S}$ is a sigma-algebra over $\mathsf{X}$. The next theorem, tells us that the sigma algebra generated by a $\pi$-system that is strictly contained inside a $\lambda$-system, is itself strictly contained into the very same $\lambda$-system.

> **$\pi$-$\lambda$ theorem**: Let $\mathsf{X}$ be a non-empty set, $\mathsf{P}\subset\mathsf{L}$ be a $\pi$-system and a $\lambda$-system over $\mathsf{X}$ respectively, then $\sigma(\mathsf{P}) \subset \mathsf{L}$.

The usefulness of this theorem is that if two probability measures agree on a $\pi$-system, then these measures agree on the sigma algebra generated by it.

> **Uniqueness of measures on $\pi$-system**: Let $\mathbb{P}$ and $\mathbb{Q}$ be two probability measures on $(\mathsf{X}, \sigma(\mathsf{P}))$, where $\mathsf{P}$ is a $\pi$-system over $\mathsf{X}$. Then
$$
\mathbb{P}(\mathsf{A}) = \mathbb{Q}(\mathsf{A}) \,\,\, \forall\,\mathsf{A}\in\mathsf{P} \implies \mathbb{P}(\mathsf{A}) = \mathbb{Q}(\mathsf{A}) \,\,\,\forall\, \mathsf{A}\in\sigma(\mathsf{P}).
$$

An important application of this is used to motivate the fact that two random variables are *equal in distribution* whenever they have the same cumulative distribution function. We express this below

> **Same CDF implies same distribution**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\mathsf{X}, \mathcal{X})$ be a measurable space with $(\mathsf{X}, \leq)$ being totally ordered, and $\mathrm{X}_1, \mathrm{X}_2:\Omega\to \mathsf{X}$ be two random variables with distributions $\mathbb{P}^{\mathrm{X}_1}$ and $\mathbb{P}^{\mathrm{X}_2}$ respectively. Then the collection of sets
$$
\mathsf{P} := \left\{ \{y\in\mathsf{X} \, : \, y\leq x\} \,:\, x\in\mathsf{X}\right\}
$$
forms a $\pi$-system, and if we define the Cumulative Distribution Function (CDF) as
$$
\mathrm{F}_{\mathrm{X}_i}(x) := \mathbb{P}_{\mathrm{X}_i}\left(\{y\in\mathsf{X}\,:\,y\leq x\}\right) = \mathbb{P}\left(\left\{\omega\in\Omega\,:\, \mathrm{X}_i(\omega) \leq x\right\}\right) =: \mathbb{P}(\mathrm{X}_i \leq x) \qquad \forall\, x\in\mathsf{X}, \,\, i=1,2,
$$
then by the $\pi$-$\lambda$ theorem, if $\mathrm{X}_1$ and $\mathrm{X}_2$ have the same CDFs, then $\mathbb{P}^{\mathrm{X}_1}$ and $\mathbb{P}^{\mathrm{X}_2}$ agree on the $\pi$-system described above and thus they also agree on $\sigma(\mathsf{P})$. Therefore, as long as we choose $\mathcal{X} \equiv \sigma(\mathsf{P})$ then we are done.

> **Cylinder sets**: 

# Stochastic Processes
A filtration is a sequence of (nested) sigma algebras that grows larger and larger. Think of it as being a historical record of information, where the $t^{\text{th}}$ sigma algebra tells you the information available at time $t$ (we call it time because usually the index is time).

> **Filtration**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and $(\mathsf{T}, \leq)$ be a totally-ordered set, which we call an index set. A filtration $\{\mathcal{F}_t\,:\, t\in\mathsf{T}\}$ induced by $(\mathsf{T}, \leq)$ is a collection of sub-sigma algebras of $\mathcal{F}$ such that $\mathcal{F}_q\subseteq\mathcal{F}_s$ when $q\leq s$.

> **Stochastic Process**: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\mathsf{X}, \mathcal{X})$ be a measurable space, and $(\mathsf{T}, \leq)$ be any totally-ordered set. The collection $\{\mathrm{X}_t\,:\, t\in\mathsf{T}\}$ of random variables $\mathrm{X}_t:\Omega\to\mathsf{X}$ is called a stochastic process. If $\mathsf{T}$ is uncountable, then it is a continuous-time stochastic process, if $\mathsf{T}$ is countable then it is a discrete-time stochastic process.

> **Path**: For $\omega\in\Omega$ **fixed** then $t\mapsto \mathrm{X}_t(\omega)$ is a function which we call the path of $\mathrm{X}_t$. 

In fact, to each $\omega\in\Omega$ there corresponds a function $t\mapsto \mathrm{X}_t(\omega)$, so that we can put $\Omega$ on a one-to-one correspondence with the space $\mathsf{X}^\mathsf{T}$ of functions from $\mathsf{T}$ to $\mathsf{X}$.


# Martingales

> **Martingale**: Let $(\mathsf{T}, \leq)$ be a totally ordered set, $(\Omega, \mathcal{F}, \mathbb{P}, \{\mathcal{F}_t\}_{t\in\mathsf{T}})$ be a filtered complete probability space, $(\mathsf{X}, \mathcal{X})$ be a measurable space and $\{\mathrm{X}_t\}_{t\in\mathsf{T}}$ be a stochastic process adapted to $\{\mathcal{F}_t\}_{t\in\mathsf{T}}$. We say that a stochastic process is a martingale with respect to $\{\mathcal{F}_t\}_{t\in\mathsf{T}}$ and $\mathbb{P}$ if \
1. $\mathbb{E}[|\mathrm{X}_t|] < \infty$ for every $t$ (meaning $\mathrm{X}_t$ is integrable) \
2. $\mathrm{X}_s = \mathbb{E}[\mathrm{X}_t \mid \mathcal{F}_s]$ for $s < t$ (meaning our best guess for $\mathrm{X}_t$ given information up to time $s$ is $\mathrm{X}_s$)



