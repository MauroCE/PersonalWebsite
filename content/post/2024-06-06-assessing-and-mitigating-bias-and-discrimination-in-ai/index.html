---
title: Holistic AI Workshop
author: Mauro Camara Escudero
date: '2023-10-11'
slug: []
categories:
  - ai-safety
  - bias
tags:
  - ai-safety
  - fairness
  - bias
subtitle: 'Assessing and Mitigating Bias and Discrimination in AI'
summary: ''
authors: []
lastmod: '2023-10-11T18:04:08+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>On October 4th 2023, Roseline Polle (Responsible AI Auditor and Researcher at Holistic AI) and Sachin Beepath (AI Assurance Officer at Holistic AI) gave us a day workshop on AI Safety, focusing an assessing and mitigating bias.</p>
<div id="trustworthy-ai" class="section level3">
<h3>Trustworthy AI</h3>
<p>The Ethical guidelines of Trustworthy AI follows 4 main verticals:</p>
<ol style="list-style-type: decimal">
<li>Robustness</li>
<li>Bias</li>
<li>Privacy</li>
<li>Explainability</li>
</ol>
<div class="float">
<img src="/trustworthy_ai.png" alt="Source: Holistic AI" />
<div class="figcaption">Source: Holistic AI</div>
</div>
</div>
<div id="case-studies" class="section level3">
<h3>Case Studies</h3>
<p>During the workshop we saw case studies for all four verticals.</p>
<ol style="list-style-type: decimal">
<li>Bias:
<ul>
<li><a href="https://blogs.lse.ac.uk/impactofsocialsciences/2020/08/26/fk-the-algorithm-what-the-world-can-learn-from-the-uks-a-level-grading-fiasco/">UK A-level grading fiasco</a>: Grades for A-level students during the pandemic were determined using an algorithm. Unfortunately, this algorithm was subject to several sources of bias, which lead to lower-than-expected grades, protests and eventually the government retracted the grades.</li>
<li><a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">COMPAS</a> predicted the likelihood of recidivism of criminals, but was found to have sever bias against black defendants: they were often considered to be at higher risk of recidivism, whereas white defendants were considered less risky. This was also true when controlling for prior crimes, age and gender.</li>
<li><a href="https://www.businessinsider.com/amazon-ai-biased-against-women-no-surprise-sandra-wachter-2018-10?r=US&amp;IR=T">Amazon Recruitment Algorithm</a> was found to discriminate against female candidates.</li>
<li><a href="http://gendershades.org">Gender Shades</a> algorithms from Microsoft, IBM and Face++ all perform better on lighter subjects, with a difference of up to 34% in error rates. Most of the misgendered faces by Face++ were of female subjects. Bias against intersectionality is exacerbated.</li>
</ul></li>
<li>Explainability
<ul>
<li><a href="https://highdemandskills.com/explainable-ai/">Cancer diagnosis</a></li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9265373/">Health Insurance Premium</a></li>
</ul></li>
<li>Robustness
<ul>
<li><a href="https://archive.nytimes.com/dealbook.nytimes.com/2012/08/02/knight-capital-says-trading-mishap-cost-it-440-million/">Knight Capital Trading Glitch</a></li>
<li><a href="https://www.bbc.co.uk/news/technology-59810383">Alexaâ€™s Penny Challenge</a></li>
</ul></li>
<li>Privacy
<ul>
<li><a href="https://www.codecademy.com/article/case-studies-notable-breaches">Uber Data Breach</a></li>
<li><a href="https://www.codecademy.com/article/case-studies-notable-breaches">Solar Winds</a></li>
</ul></li>
</ol>
</div>
<div id="sources-of-bias" class="section level3">
<h3>Sources of Bias</h3>
<div class="float">
<img src="/sources_of_bias.png" alt="Source: Holistic AI" />
<div class="figcaption">Source: Holistic AI</div>
</div>
<p>structured as follows:</p>
<ol style="list-style-type: decimal">
<li>Teaching Session:
<ol style="list-style-type: decimal">
<li>30m Talk: Introduction to <strong>Trustworthy AI</strong>, with a focus on <strong>Bias</strong> and <strong>Fairness</strong> although they touched upon other verticals such as <strong>Explainability</strong>, <strong>Privacy</strong>, and <strong>Robustness</strong>.</li>
<li>30min Talk: Sources of Bias. Equality of Opportunity vs Equality of Outcome.</li>
<li>20min Talk: Measuring Bias in <strong>Binary Classification</strong>.</li>
<li>30min Talk: Mitigating bias in Binary Classification.</li>
<li>30min Talk: Trade-offs and other verticals such as Explainability and Robustness.</li>
</ol></li>
<li>Practical Session:
<ol style="list-style-type: decimal">
<li>Measure and Mitigate in Binary classification using recruitment data and holisticai library (Equality of Outcome). Several mitigation techniques were explored.</li>
<li>Measure and Mitigate bias in a face recognition application (Equality of Opportunity). Several mitigation techniques were explored.</li>
<li>Explore trade-offs with other verticals, with a focus on explainability (SHAP, LIME, Feature importance)</li>
</ol></li>
</ol>
</div>
