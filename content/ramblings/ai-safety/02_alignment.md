---
title: "Large Language Models can Strategically Deceive their Users when put under pressure"
linktitle: 
toc: true
type: docs
date: "2024-06-04T00:00:00+01:00"
draft: false
menu:
  ai-safety:
    parent: 1) Alignment
    weight: 2

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 31
---
Existence proof that GPT-4 can performed misaligned actions, perform strategic deception and double down on it when put under enough pressure. The type of pressure seems irrelevant, but the quantity of pressure sources seems to make a difference.
